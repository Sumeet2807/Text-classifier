---
# data:
#   train:
#     class: 'flat.Delimited_file'
#     text-column: '3'
#     label-column: '2'
#     shuffle: true
#     fraction: 0.01
#     remove-null-text: true
#     args:
#       filepath: '../data/twitter_training.csv'
#       seperator: ','

  # test: 
  #   class: 'flat.Delimited_file'
  #   text-column: '3'
  #   label-column: '2'
  #   shuffle: true
  #   fraction: 0.01
  #   remove-null-text: true
  #   args:
  #     filepath: '../data/twitter_training.csv'
  #     seperator: ','

data:
  train:
    class: 'flat.Delimited_file'
    text-column: 'text_cleaned'
    label-column: 'target'
    shuffle: true
    fraction: 0.005
    remove-null-text: true
    args:
      filepath: '../data/20newsgroup_preprocessed.csv'
      seperator: ';'





preprocessing:
  class: 'vanilla.Processor'
  args:
    remove-garbage-words: true
    remove-numbers: true
    remove-stopwords: false
    lemmatize: false
    force-lower-case: true
    core-words: null





# model:
#   class: 'bow.Linear_ensemble'
#   save-dir: '../export/'
#   args:
#     vectorizer-type: 'tfidf'
#     vectorizer-max-features: 10000
#     vectorizer-ngrams: 
#       - 1 #min
#       - 1 #max
#     clf-penalty: 'none'
#     clf-max-iter: 10000
#     clf-solver: 'lbfgs'
#     ensemble-groups: 10
#     ensemble-folds: 8
#     scale-inputs: true

# model:
#   class: 'bow.Linear_ensemble_sgd'
#   save-dir: null
#   args:
#     vectorizer-type: 'tfidf'
#     vectorizer-max-features: 10000
#     vectorizer-ngrams: 
#       - 1 #min
#       - 1 #max
#     clf-penalty: 'none'
#     clf-max-iter: 1000
#     clf-loss: 'log_loss'
#     clf-early-stop: True
#     ensemble-groups: 3
#     ensemble-folds: 5
#     scale-inputs: true

# model:
#   class: 'rnn.BLSTM'
#   # save-dir: '../export/'
#   save-dir: null
#   args:
#     vectorizer-max-vocab-size: 20000
#     max-epochs: 100
#     early-stop-patience: 5
#     recurrent-architecture:
#       - 8
#     dense-architecture:
#       - 8
#     embedding-size: 8
#     learning-rate: 0.001
#     dropout-rate: 0.2
#     batch-size: 32
#     validation-to-train-ratio: 0.1

model:
  class: 'bert.Dense_top'
  # save-dir: '../export/'
  save-dir: null
  args:
    max-epochs: 1
    early-stop-patience: 5
    learning-rate: 0.001
    batch-size: 32
    validation-to-train-ratio: 0.1
    dense-top-size: 8
    finetune-whole-bert: false