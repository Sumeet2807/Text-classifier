{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BREAL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\BREAL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** Loading training data ******\n",
      "\n",
      "\n",
      "****** Training model - rnn.BLSTM ******\n",
      "21/21 [==============================] - 12s 194ms/step - loss: 1.3862 - accuracy: 0.2583 - val_loss: 1.3843 - val_accuracy: 0.2466\n",
      "loss - 1.3861863613128662\n",
      "accuracy - 0.25825825333595276\n",
      "val_loss - 1.384305715560913\n",
      "val_accuracy - 0.24657534062862396\n",
      "\n",
      "\n",
      "****** Testing model ******\n",
      "23/23 [==============================] - 3s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00       134\n",
      "    Negative       0.35      0.09      0.14       211\n",
      "     Neutral       0.39      0.07      0.12       182\n",
      "    Positive       0.29      0.90      0.44       209\n",
      "\n",
      "    accuracy                           0.30       736\n",
      "   macro avg       0.26      0.27      0.18       736\n",
      "weighted avg       0.28      0.30      0.20       736\n",
      "\n",
      "\n",
      "\n",
      "****** Saving model ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../export/1669249617\\net\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../export/1669249617\\net\\assets\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.utils import get_preprocessor_class\n",
    "from models.utils import get_model_class\n",
    "import yaml\n",
    "from sklearn.metrics import classification_report as cr\n",
    "from utils import get_data_from_config\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "with open(\"config_train.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "\n",
    "preprocess_config = config['preprocessing']\n",
    "model_config = config['model']\n",
    "data_config = config['data']\n",
    "\n",
    "preprocessor = get_preprocessor_class(preprocess_config['class'])(preprocess_config['args'])\n",
    "model = get_model_class(model_config['class'])(model_config['args'])\n",
    "\n",
    "\n",
    "print(\"\\n\\n****** Loading training data ******\")\n",
    "\n",
    "_,X_train,y_train = get_data_from_config(data_config['train'],preprocessor)\n",
    "\n",
    "\n",
    "print('\\n\\n****** Training model - %s ******' % model_config['class'])\n",
    "model.fit(X_train,y_train)\n",
    "model.report_metrics()\n",
    "\n",
    "if 'test' in data_config:\n",
    "\n",
    "    test_data_config = data_config['test']\n",
    "    _,X_test,y_test = get_data_from_config(test_data_config,preprocessor)\n",
    "\n",
    "    print('\\n\\n****** Testing model ******')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(cr(y_test,y_pred, zero_division=0))\n",
    "\n",
    "if model_config['save-dir'] is not None:\n",
    "    print('\\n\\n****** Saving model ******')\n",
    "\n",
    "    if not os.path.exists(model_config['save-dir']):\n",
    "        os.makedirs(model_config['save-dir'])\n",
    "    tstamp = str(int(time.time()))\n",
    "    save_object_name = os.path.join(model_config['save-dir'],tstamp)\n",
    "    save_object_name = model.save(save_object_name)\n",
    "    model_config['saved-object'] = save_object_name\n",
    "    yaml_filename = os.path.join(model_config['save-dir'],tstamp + '.yml')\n",
    "    with open(yaml_filename, 'w+') as yaml_file:\n",
    "        yaml.dump(config, yaml_file, allow_unicode=True, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** Loading model ******\n",
      "../export/1669247598\\net\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://f28b4c73-01d0-4abf-a3c2-3af183e1b315/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m preprocessor \u001b[39m=\u001b[39m get_preprocessor_class(preprocess_config[\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m])(preprocess_config[\u001b[39m'\u001b[39m\u001b[39margs\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m****** Loading model ******\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m model \u001b[39m=\u001b[39m get_model_class(model_config[\u001b[39m'\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m'\u001b[39;49m])(model_config[\u001b[39m'\u001b[39;49m\u001b[39margs\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49mload(model_config[\u001b[39m'\u001b[39;49m\u001b[39msaved-object\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     29\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m****** Loading data from source******\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m df,X,_ \u001b[39m=\u001b[39m get_data_from_config(data_config[\u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Sumeet\\Desktop\\Projects\\Text-classifier\\src\\models\\rnn.py:122\u001b[0m, in \u001b[0;36mBLSTM.load\u001b[1;34m(self, object_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mprint\u001b[39m(net_path)\n\u001b[0;32m    121\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(wrapper_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m pkl_file:\n\u001b[1;32m--> 122\u001b[0m     model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(pkl_file)\n\u001b[0;32m    123\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39myay\u001b[39m\u001b[39m'\u001b[39m)        \n\u001b[0;32m    124\u001b[0m model\u001b[39m.\u001b[39mnet \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(net_path)\n",
      "File \u001b[1;32mc:\\Users\\BREAL\\miniconda3\\envs\\myml\\lib\\site-packages\\keras\\saving\\pickle_utils.py:48\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     46\u001b[0m       \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mGFile(dest_path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     47\u001b[0m         f\u001b[39m.\u001b[39mwrite(archive\u001b[39m.\u001b[39mextractfile(name)\u001b[39m.\u001b[39mread())\n\u001b[1;32m---> 48\u001b[0m model \u001b[39m=\u001b[39m save_module\u001b[39m.\u001b[39;49mload_model(temp_dir)\n\u001b[0;32m     49\u001b[0m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mrmtree(temp_dir)\n\u001b[0;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\BREAL\\miniconda3\\envs\\myml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\BREAL\\miniconda3\\envs\\myml\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:915\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    912\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    913\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    914\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 915\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m       \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    918\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    919\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    920\u001b[0m root \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n\u001b[0;32m    921\u001b[0m root\u001b[39m.\u001b[39mgraph_debug_info \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://f28b4c73-01d0-4abf-a3c2-3af183e1b315/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from preprocessing.utils import get_preprocessor_class\n",
    "from models.utils import get_model_class\n",
    "from data_io.utils import get_datahandler_class\n",
    "from utils import get_data_from_config\n",
    "\n",
    "import yaml\n",
    "from sklearn.metrics import classification_report as cr\n",
    "\n",
    "\n",
    "with open(\"config_predict.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config\n",
    "\n",
    "data_config = config['data']\n",
    "\n",
    "with open(config['model']['yml-path'], \"r\") as f:\n",
    "    model_yml = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "\n",
    "preprocess_config = model_yml['preprocessing']\n",
    "model_config = model_yml['model']\n",
    "preprocessor = get_preprocessor_class(preprocess_config['class'])(preprocess_config['args'])\n",
    "print(\"\\n\\n****** Loading model ******\")\n",
    "\n",
    "model = get_model_class(model_config['class'])(model_config['args']).load(model_config['saved-object'])\n",
    "print(\"\\n\\n****** Loading data from source******\")\n",
    "\n",
    "df,X,_ = get_data_from_config(data_config['read'])\n",
    "\n",
    "print(\"\\n\\n****** Predicting ******\")\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "if 'write' in config['data']:\n",
    "    print(\"\\n\\n****** Writing predictions to destination******\")\n",
    "\n",
    "    df[data_config['write']['label-column']] = y_pred\n",
    "    get_datahandler_class(data_config['write']['class'])().write(df,data_config['write']['args'])\n",
    "\n",
    "\n",
    "\n",
    "# print('\\n\\n****** Training model - %s ******' % model_config['class'])\n",
    "# model.fit(X_train,y_train)\n",
    "# model.report_metrics()\n",
    "\n",
    "# if 'test' in data_config:\n",
    "#     test_data_handler = get_datahandler_instance(data_config['train'])\n",
    "\n",
    "#     X_test,y_test = test_data_handler.read(data_config['test']['text-column'],data_config['test']['args'],\n",
    "#                                             data_config['test']['label-column'],text_preprocessing=preprocessor)\n",
    "#     print('\\n\\n****** Testing model ******')\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print(cr(y_test,y_pred, zero_division=0))\n",
    "\n",
    "# print('\\n\\n****** Saving model ******')\n",
    "# model.save(model_config['save-dir'],config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import pickle\n",
    "# tf.keras.models.load_model('..\\\\export\\\\1669245060\\\\model\\\\net')\n",
    "\n",
    "path = 'C:\\\\Users\\\\Sumeet\\\\Desktop\\\\Projects\\\\Text-classifier\\\\export\\\\1669249617\\\\wrapper'\n",
    "\n",
    "with open(path, 'rb') as pkl_file:\n",
    "    model = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BREAL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\BREAL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** Loading training data ******\n",
      "\n",
      "\n",
      "****** Training model - rnn.BLSTM ******\n",
      "21/21 [==============================] - 13s 191ms/step - loss: 1.3855 - accuracy: 0.2620 - val_loss: 1.3863 - val_accuracy: 0.2568\n",
      "loss - 1.3855092525482178\n",
      "accuracy - 0.261976033449173\n",
      "val_loss - 1.3863126039505005\n",
      "val_accuracy - 0.2567567527294159\n",
      "\n",
      "\n",
      "****** Testing model ******\n",
      "23/23 [==============================] - 3s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00       125\n",
      "    Negative       0.32      0.36      0.34       229\n",
      "     Neutral       0.00      0.00      0.00       179\n",
      "    Positive       0.31      0.72      0.43       203\n",
      "\n",
      "    accuracy                           0.31       736\n",
      "   macro avg       0.16      0.27      0.19       736\n",
      "weighted avg       0.18      0.31      0.23       736\n",
      "\n",
      "\n",
      "\n",
      "****** Saving model ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../export/1669249786\\model\\net\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../export/1669249786\\model\\net\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved at - ../export/1669249786\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.utils import get_preprocessor_class\n",
    "from models.utils import get_model_class\n",
    "import yaml\n",
    "from sklearn.metrics import classification_report as cr\n",
    "from utils import get_data_from_config\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "with open(\"config_train.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "\n",
    "preprocess_config = config['preprocessing']\n",
    "model_config = config['model']\n",
    "data_config = config['data']\n",
    "\n",
    "preprocessor = get_preprocessor_class(preprocess_config['class'])(preprocess_config['args'])\n",
    "model = get_model_class(model_config['class'])(model_config['args'])\n",
    "\n",
    "\n",
    "print(\"\\n\\n****** Loading training data ******\")\n",
    "\n",
    "_,X_train,y_train = get_data_from_config(data_config['train'],preprocessor)\n",
    "\n",
    "\n",
    "print('\\n\\n****** Training model - %s ******' % model_config['class'])\n",
    "model.fit(X_train,y_train)\n",
    "model.report_metrics()\n",
    "\n",
    "if 'test' in data_config:\n",
    "\n",
    "    test_data_config = data_config['test']\n",
    "    _,X_test,y_test = get_data_from_config(test_data_config,preprocessor)\n",
    "\n",
    "    print('\\n\\n****** Testing model ******')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(cr(y_test,y_pred, zero_division=0))\n",
    "\n",
    "if model_config['save-dir'] is not None:\n",
    "    print('\\n\\n****** Saving model ******')\n",
    "    save_folder = os.path.join(model_config['save-dir'],str(int(time.time())))\n",
    "    os.makedirs(save_folder,exist_ok=True)\n",
    "    save_object_name = os.path.join(save_folder,'model')\n",
    "    save_object_name = model.save(save_object_name)\n",
    "    model_config['saved-object'] = save_object_name\n",
    "    yaml_filename = os.path.join(save_folder,'specs' + '.yml')\n",
    "    with open(yaml_filename, 'w+') as yaml_file:\n",
    "        yaml.dump(config, yaml_file, allow_unicode=True, default_flow_style=False)\n",
    "    print('model saved at - %s' % save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** Loading model ******\n",
      "../export/1669249786\\model\\net\n",
      "yay\n",
      "\n",
      "\n",
      "****** Loading data from source******\n",
      "\n",
      "\n",
      "****** Predicting ******\n",
      "24/24 [==============================] - 3s 8ms/step\n",
      "\n",
      "\n",
      "****** Writing predictions to destination******\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from preprocessing.utils import get_preprocessor_class\n",
    "from models.utils import get_model_class\n",
    "from data_io.utils import get_datahandler_class\n",
    "from utils import get_data_from_config\n",
    "\n",
    "import yaml\n",
    "from sklearn.metrics import classification_report as cr\n",
    "\n",
    "\n",
    "with open(\"config_predict.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config\n",
    "\n",
    "data_config = config['data']\n",
    "\n",
    "yaml_filename = os.path.join(config['model']['path'],'specs' + '.yml')\n",
    "with open(yaml_filename, \"r\") as f:\n",
    "    model_yml = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "\n",
    "preprocess_config = model_yml['preprocessing']\n",
    "model_config = model_yml['model']\n",
    "preprocessor = get_preprocessor_class(preprocess_config['class'])(preprocess_config['args'])\n",
    "print(\"\\n\\n****** Loading model ******\")\n",
    "\n",
    "model = get_model_class(model_config['class'])(model_config['args']).load(model_config['saved-object'])\n",
    "print(\"\\n\\n****** Loading data from source******\")\n",
    "\n",
    "df,X,_ = get_data_from_config(data_config['read'])\n",
    "\n",
    "print(\"\\n\\n****** Predicting ******\")\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "if 'write' in config['data']:\n",
    "    print(\"\\n\\n****** Writing predictions to destination******\")\n",
    "\n",
    "    df[data_config['write']['label-column']] = y_pred\n",
    "    get_datahandler_class(data_config['write']['class'])().write(df,data_config['write']['args'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('myml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f989cabc84b8a0968abfa9f17541d9ce83f18097a2bafd26401b884a6137c111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
